# Maia_gaze4holo
Gaze based interaction and error detection (TCN autoencoder) for hololens2 under MAIA research project
- 3D hologram objects can get selected: Stable
- Objects detected by a pretrained YOLO model: Unstable

# Dependencies and other potentially helpful information
- Unity Version: 2022.3.23f1 (LTS). 
- Universal Platform Build Support V143 (ARM64/ARM64EC)
- Visual Studio Code: 1.96.4.
    - Net install tool .NET Install Tool  v2.2.5
    - C#  v2.61.28
    - C# Dev Kit  v1.15.34
    - Windows 10 SDK: 10.0.19041
    - Mixed Reality Feature Toolkit: The latest version (v1.0.2209.0)
- Packages I downloaded from repos and added from disk
  - Barracuda: 3.0.1
  - RealityCollective.Service-Framework: 1.0.8
  - RealityCollective.Utilities: 1.0.13

# Research supported by
This research is supported by European Union's Horizon 2020 research and innovation program under grant agreement No.951910 (MAIA)

# App based Research
Contents of app are based on the following research

Severitt, B. R., Castner, N., & Wahl, S. (2024). Bi-Directional Gaze-Based Communication: A Review. Multimodal Technologies and Interaction, 8(12), 108.

Severitt, B. R., Sauer, Y., Castner, N., Fuhl, W., & Wahl, S. (2025). Recognition of errors in gaze-based interaction with anomaly detection. Accepted at COGAIN symposium as part of the ACM Symposium of Eye Tracking Research & Applications (ETRA).

# Inspiration for parts of the code
Thank you "LocalJoost" for your break down of object detection in AR, have borrowed some code and assets, but currently not using

[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/CatsNur/Maia_gaze4holo)
